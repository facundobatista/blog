2010-12-03 23:22:52
Muchas lecturas aleatorias y secuenciales, ¿mmap?
<tags>

 Con Guillo y Alecu empezamos a charlar sobre si, en un módulo que estaba haciendo Guillo para el <a href="http://launchpad.net/ubuntuone-client">laburo</a> convenía usar <a href="http://en.wikipedia.org/wiki/Mmap">mmap</a> al tener muchas lecturas secuenciales y muchas lecturas aletorias sobre un archivo grande. Obviamente, usando Python (¿faltaba aclararlo?).

 Como no nos decidíamos, decidí medirlo.

 <a href="http://www.flickr.com/photos/61863636@N00/1533299418/"><img src="http://www.taniquetil.com.ar/facundo/imgs/medir.jpg" alt="Medimos!" width="400" height="266" /></a>

 Creé un archivo de cien millones de bytes al azar, y probé con <a href="http://www.taniquetil.com.ar/facundo/bdvfiles/code/test_mmap_scripts.tar.gz">distintos scripts hechos en el momento</a>, con un comportamiento parecido al que iba a hacer Guillo:</p>
<ul>
<li>Una lectura secuencial de todo el archivo, de a dos tamaños diferentes. En el script leo 50 bytes, y luego 450 bytes, y así; en la realidad se haría una lectura de ~50 bytes, longitud fija, y luego una de ~450, longitud variable.

<li>Doscientas mil lecturas al azar en todo el archivo, siempre de 450 bytes. En la realidad, se harían muchas lecturas, de un valor no fijo pero precalculado.

</ul>
<p>En ambos casos, las pruebas que realicé fueron haciendo .read() y .seek() sobre archivos normales, haciendo .read() y .seek() sobre el mmap, y usando el mmap como un string, accediendo por slices.

 <strong>Resultados</strong>

 Entonces, lectura secuencial, leyendo los cien megabytes de principio a fin (en milisegundos):

 <span style="font-family: courier new,courier;">- .read() y seek() sobre el file: 501 mseg
 - .read() y seek() sobre el mmap: 492 mseg
 - usando slices sobre el mmap:&nbsp;&nbsp; 169 mseg</span>

 Es notable la diferencia.

 Hay que tener en cuenta que los primeros dos hacen dos llamadas a función por cada vuelta del loop (vean los archivos para más detalle), lo que suma 400 mil function calls en total. Yo había medido antes el costo de una llamada a función, y eran de un poco menos de 250 nanogundos: no parece mucho, pero en 400 mil llamadas, suman 100 milisegundos, lo que explica un poco la diferencia en lo medido.

 En la lectura secuencial, tiempo total desde que se tiene la posición a leer hasta que se obtiene el string (en microsegundos):

 <span style="font-family: courier new,courier;">- .read() y seek() sobre el file: 18.1 useg
 - .read() y seek() sobre el mmap: 10.8 useg
 - usando slices sobre el mmap:&nbsp;&nbsp; 10.3 useg</span>

 <strong>Conclusiones</strong>

 Si vamos a usar mmap, en estos casos, conviene usar el acceso por slices (con corchetes). &nbsp;

 Tomando esos tiempos, mmap es un<em> 296% más rápido</em> en la lectura secuencial, y un <em>75% más rápido</em> en el acceso aleatorio.

 Claramente mmap es el ganador.

 <strong>Disclaimers</strong>

 Uno: Esto lo hice usando Python 2.6.6 en un Linux.

 Dos: Mi disco es un SSD, seguramente en un disco con platos magnéticos la diferencia entre acceso secuencial y acceso aleatorio sea mayor.

 Tres: Inmediatamente antes de hacer cada prueba, hay que decirle al sistema operativo que descarte los caches del filesystem, para que esto no nos deforme las medidas. Eso lo hice con <a href="http://www.taniquetil.com.ar/homedevel/utils/drop_cache.sh">este script</a>.</p> |
